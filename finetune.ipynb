{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import paddle\n",
    "from paddlenlp.datasets import load_dataset\n",
    "from paddlenlp.transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from paddlenlp.trainer import Trainer, TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-05-24 10:15:24,851] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.ernie.modeling.ErnieForSequenceClassification'> to load 'ernie-1.0-base-zh'.\u001b[0m\n",
      "\u001b[32m[2022-05-24 10:15:24,855] [    INFO]\u001b[0m - Already cached /home/ricardo/.paddlenlp/models/ernie-1.0-base-zh/ernie_v1_chn_base.pdparams\u001b[0m\n",
      "\u001b[32m[2022-05-24 10:15:38,888] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load 'ernie-1.0-base-zh'.\u001b[0m\n",
      "\u001b[32m[2022-05-24 10:15:38,890] [    INFO]\u001b[0m - Already cached /home/ricardo/.paddlenlp/models/ernie-1.0-base-zh/vocab.txt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"chnsenticorp\", splits=[\"train\"])\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ernie-1.0-base-zh\", num_classes=len(train_dataset.label_list))\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ernie-1.0-base-zh\")\n",
    "\n",
    "def convert_example(example, tokenizer):\n",
    "    encoded_inputs = tokenizer(text=example[\"text\"], max_seq_len=128, pad_to_max_seq_len=True)\n",
    "    encoded_inputs[\"labels\"] = int(example[\"label\"])\n",
    "    return encoded_inputs\n",
    "\n",
    "train_dataset = train_dataset.map(partial(convert_example, tokenizer=tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1, 250, 371, 243, 850, 4, 160, 850, 36, 4, 898, 1143, 614, 356, 165, 201, 340, 88, 5, 12043, 196, 13, 131, 7, 218, 11, 560, 242, 817, 122, 4, 28, 232, 160, 850, 4, 335, 45, 850, 49, 4, 238, 559, 16, 675, 111, 100, 207, 358, 281, 12043, 785, 51, 10, 243, 100, 40, 850, 12043, 47, 218, 276, 505, 4, 169, 1741, 957, 4, 1266, 500, 1010, 28, 86, 269, 4, 1701, 500, 28, 1598, 486, 28, 61, 335, 86, 4, 982, 187, 34, 87, 9, 102, 871, 579, 1593, 87, 999, 183, 4, 201, 170, 75, 10, 28, 232, 160, 850, 5, 4, 466, 28, 370, 566, 1266, 500, 5, 269, 4, 118, 102, 311, 86, 15, 27, 269, 4, 244, 15, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments('./output')\n",
    "training_args.do_train = True\n",
    "training_args.evaluation_strategy = 'steps'\n",
    "# print(training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_MSE(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Custom_MSE, self).__init__()\n",
    "\n",
    "    def forward(self, predictions, target):\n",
    "        square_difference = paddle.square(predictions - target)\n",
    "        loss_value = paddle.mean(square_difference)\n",
    "        return loss_value\n",
    "    \n",
    "    # def __call__(self, predictions, target):\n",
    "    #   square_difference = paddle.square(y_predictions - target)\n",
    "    #   loss_value = paddle.mean(square_difference)\n",
    "    #   return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     criterion=paddle.nn.loss.CrossEntropyLoss(),\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset if training_args.do_train else None,\n",
    "#     tokenizer=tokenizer)\n",
    "\n",
    "# if training_args.do_train:\n",
    "#     train_result = trainer.train()\n",
    "#     metrics = train_result.metrics\n",
    "#     trainer.save_model()\n",
    "#     trainer.log_metrics(\"train\", metrics)\n",
    "#     trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "077e27cbed4bc4ef53cb87468badd11a7a60a73d7494d4644aa5441d1d891a61"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('PaddleEE')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
